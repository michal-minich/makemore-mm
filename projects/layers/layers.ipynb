{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from datetime import datetime\n",
    "import math\n",
    "import random\n",
    "import numpy as NP\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "relPath = \"../../\"\n",
    "import sys\n",
    "sys.path.append(relPath)\n",
    "from mm.printing import *\n",
    "from mm.neural.neural import *\n",
    "from introspection import *\n",
    "from layers import *\n",
    "from network import *\n",
    "from neural import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common init:         -------------------------- 2023-07-21 14:44:47\n",
      "dtype:               torch.float32\n",
      "device:              cpu\n",
      "contextSize:         3\n",
      "newNet:              True\n"
     ]
    }
   ],
   "source": [
    "initLogging(\"Common init\")\n",
    "\n",
    "dtype = torch.float\n",
    "log(\"dtype\", dtype)\n",
    "\n",
    "dvc = torch.device(\"cpu\")\n",
    "log(\"device\", dvc.type)\n",
    "\n",
    "contextSize = 3\n",
    "log(\"contextSize\", contextSize)\n",
    "\n",
    "newNet = True\n",
    "log(\"newNet\", newNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data:        -------------------------- 2023-07-21 14:44:48\n",
      "filePath:            ../../data/names.txt\n",
      "trRatio:             0.8\n",
      "devRatio:            0.9\n",
      "wordShufflingSeed:   42\n",
      "first few words:     ['yuheng', 'diondre', 'xavien', 'jori', 'juanluis']\n",
      "lenWords:            32033\n",
      "allPossibleChars:    ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "stoi:                {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "itos:                {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "vocabularyLength:    27\n",
      "data random probability: 3.2958\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Prepare data\")\n",
    "\n",
    "filePath = relPath + \"data/names.txt\"\n",
    "log(\"filePath\", filePath)\n",
    "\n",
    "trRatio = 0.8\n",
    "log(\"trRatio\", trRatio)\n",
    "\n",
    "devRatio = 0.9\n",
    "log(\"devRatio\", devRatio)\n",
    "\n",
    "wordShufflingSeed = 42\n",
    "log(\"wordShufflingSeed\", wordShufflingSeed)\n",
    "\n",
    "words = readFileSplitByLine(filePath)\n",
    "random.seed(wordShufflingSeed)\n",
    "random.shuffle(words)\n",
    "log(\"first few words\", words[:5])\n",
    "\n",
    "lenWords = len(words);\n",
    "log(\"lenWords\", lenWords)\n",
    "\n",
    "allPossibleChars = sorted(list(set(\"\".join(words))))\n",
    "log(\"allPossibleChars\", allPossibleChars)\n",
    "\n",
    "stoi = sToI(allPossibleChars)\n",
    "log(\"stoi\", stoi)\n",
    "\n",
    "itos = iToS(stoi)\n",
    "log(\"itos\", itos)\n",
    "\n",
    "vocabularyLength = len(itos)\n",
    "log(\"vocabularyLength\", vocabularyLength)\n",
    "\n",
    "log(\"data random probability\", f\"{-torch.tensor(1 / vocabularyLength).log().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare dataset:     -------------------------- 2023-07-21 14:44:48\n",
      "data dtype:          torch.int64\n",
      "data set training:   25626 torch.Size([182625, 3]) torch.Size([182625]) ['yuheng', 'diondre', 'xavien']\n",
      "data set validation: 3203 torch.Size([22655, 3]) torch.Size([22655]) ['amay', 'aytana', 'jenevi']\n",
      "data set test:       3204 torch.Size([22866, 3]) torch.Size([22866]) ['mustafa', 'reuben', 'kahlel']\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Prepare dataset\")\n",
    "\n",
    "dataDtype = torch.int64\n",
    "log(\"data dtype\", dataDtype)\n",
    "\n",
    "lenTrain = int(trRatio * lenWords)\n",
    "trWords = words[:lenTrain]\n",
    "trX, trY = buildDataSet(trWords, contextSize, stoi, itos, dataDtype, dvc)\n",
    "log(\"data set training\", lenTrain, trX.shape, trY.shape, trWords[:3])\n",
    "\n",
    "endVal = int(devRatio * lenWords)\n",
    "valWords = words[lenTrain:endVal];\n",
    "valX, valY = buildDataSet(valWords, contextSize, stoi, itos, dataDtype, dvc)\n",
    "log(\"data set validation\", endVal - lenTrain, valX.shape, valY.shape, valWords[:3])\n",
    "\n",
    "lenTest = lenWords - endVal\n",
    "tstWords = words[endVal:]\n",
    "tstX, tstY = buildDataSet(tstWords, contextSize, stoi, itos, dataDtype, dvc)\n",
    "log(\"data set test\", lenTest, tstX.shape, tstY.shape, tstWords[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build network:       -------------------------- 2023-07-21 14:44:48\n",
      "embeddingDims:       10\n",
      "hiddenLayerSize:     200\n",
      "learningSeed:        2147483647\n",
      "Network Structure:  \n",
      "Layer LinearWithBias 22284: torch.Size([30, 200]), torch.Size([200]), \n",
      "Layer Tanh 22285: \n",
      "Layer LinearWithBias 22286: torch.Size([200, 200]), torch.Size([200]), \n",
      "Parameters Count:    46670\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Build network\")\n",
    "\n",
    "embeddingDims = 10\n",
    "log(\"embeddingDims\", embeddingDims)\n",
    "\n",
    "hiddenLayerSize = 200\n",
    "log(\"hiddenLayerSize\", hiddenLayerSize)\n",
    "\n",
    "learningSeed = 2147483647\n",
    "log(\"learningSeed\", learningSeed)\n",
    "g = torch.Generator(device=dvc).manual_seed(learningSeed)\n",
    "\n",
    "np2 = makeNetwork2(g, vocabularyLength, embeddingDims, contextSize, hiddenLayerSize, dtype, dvc)\n",
    "printNetwork(np2)\n",
    "    \n",
    "@torch.no_grad()\n",
    "def trLoss2(): return getLoss2(np2, np2.C[trX], trY)\n",
    "\n",
    "@torch.no_grad()\n",
    "def valLoss2(): return getLoss2(np2, np2.C[valX], valY)\n",
    "\n",
    "@torch.no_grad()\n",
    "def tstLoss2(): return getLoss2(np2, np2.C[tstX], tstY)\n",
    "\n",
    "def getLosses2() -> Losses2:\n",
    "    l = Losses2()\n",
    "    l.tr = trLoss2()\n",
    "    l.val = valLoss2()\n",
    "    l.tst = tstLoss2()\n",
    "    return l\n",
    "\n",
    "def logLosses2():\n",
    "    losses = getLosses2()\n",
    "    l1 = f\"{losses.tr.loss.item():>10.4f}\"\n",
    "    l2 = f\"{losses.val.loss.item():>10.4f}\"\n",
    "    l3 = f\"{losses.tst.loss.item():>10.4f}\"\n",
    "    logSimple(f\"{l1} {l2} {l3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning:            -------------------------- 2023-07-21 14:44:48\n",
      "trainingBatchSize:   32\n",
      "trainingSteps: :     5708\n",
      "maxIteration:        20000\n",
      "repeats:             36\n",
      "maxLr:               0.14\n",
      "minLr:               0.0001\n",
      "actualIterations:    20000\n",
      "  0,      0 losses:     0.0000       5.2987     5.2984     5.2988\n",
      "  1,   5708 losses:     2.7872       2.3467     2.3427     2.3464\n",
      "  2,  11416 losses:     2.4146       2.3017     2.3005     2.3052\n",
      "  3,  17124 losses:     2.0725       2.2665     2.2678     2.2699\n",
      "Break at max iteration:\n",
      " final losses:          1.9495       2.2575     2.2586     2.2608\n",
      "emb.shape:           torch.Size([32, 3, 10])\n",
      "logits.shape:        torch.Size([32, 200])\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Learning\")\n",
    "\n",
    "trainingBatchSize = 32\n",
    "log(\"trainingBatchSize\", trainingBatchSize)\n",
    "\n",
    "trXLength = trX.shape[0]\n",
    "trainingSteps = (trXLength // trainingBatchSize) + 1\n",
    "log (\"trainingSteps: \", trainingSteps)\n",
    "\n",
    "maxIteration = 20_000\n",
    "log(\"maxIteration\", maxIteration)\n",
    "\n",
    "repeats = 36\n",
    "log(\"repeats\",repeats)\n",
    "\n",
    "maxLr = 0.14\n",
    "log(\"maxLr\", maxLr)\n",
    "\n",
    "minLr = 0.0001\n",
    "log(\"minLr\", minLr)\n",
    "\n",
    "actualIterations = min(maxIteration, repeats * math.ceil(trXLength / trainingBatchSize))\n",
    "log(\"actualIterations\", actualIterations)\n",
    "\n",
    "lrAtIx: list[float] = []\n",
    "stepIx: list[int] = []\n",
    "lossAtIx: list[float] = []\n",
    "logLossAtIx: list[float] = []\n",
    "up = UpdateNetResult()\n",
    "fr = ForwardPassResult2()\n",
    "fr.loss = torch.tensor(0)\n",
    "i = 0\n",
    "bnMeanRunning = 0\n",
    "bnStdRunning = 0\n",
    "for repeat in range(repeats):\n",
    "    \n",
    "    if i >= maxIteration:\n",
    "        break;\n",
    "\n",
    "    logSimple(f\"{repeat:>3}, {i:>6} losses: {fr.loss.item():>10.4f}   \", end=\"\")\n",
    "    logLosses2()\n",
    "\n",
    "    for start in range(0, trXLength, trainingBatchSize):\n",
    "\n",
    "        if i >= maxIteration:\n",
    "            log(\"Break at max iteration\")\n",
    "            break;\n",
    "        \n",
    "        end = min(start + trainingBatchSize, trXLength)\n",
    "        miniBatchIxs = torch.randint(0, trXLength, (trainingBatchSize,), generator=g, device=dvc)\n",
    "        fr = forwardPass2(np2, trX, trY, miniBatchIxs)\n",
    "        backwardPass2(np2.layers, np2.parameters, fr.loss)\n",
    "\n",
    "        up = updateNet(np2.parameters, i, actualIterations, maxLr, minLr)\n",
    "        lrAtIx.append(up.learningRate)\n",
    "\n",
    "        stepIx.append(i)\n",
    "        lossAtIx.append(fr.loss.item())\n",
    "        logLossAtIx.append(fr.loss.log10().item())\n",
    "\n",
    "        i += 1\n",
    "\n",
    "logSimple(f\" final losses: {fr.loss.item():>15.4f}   \", end=\"\")\n",
    "logLosses2()\n",
    "\n",
    "#bestLr = lrs[findLowestIndex(lossAtIx)].item();\n",
    "#log(\"best learning rate\", bestLr)\n",
    "log(\"emb.shape\", fr.emb.shape)\n",
    "#log(\"h.shape\", fr.h.shape)\n",
    "log(\"logits.shape\", fr.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling:            -------------------------- 2023-07-21 14:45:10\n",
      "samplingSeed:        2147483657\n",
      "maxSampleLength:     50\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Sampling\")\n",
    "\n",
    "samplingSeed = learningSeed + 10\n",
    "gSampling = torch.Generator(device=dvc).manual_seed(samplingSeed)\n",
    "log(\"samplingSeed\", samplingSeed)\n",
    "\n",
    "maxSampleLength = 50\n",
    "log(\"maxSampleLength\", maxSampleLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "190",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m samples \u001b[39m=\u001b[39m sampleMany2(np2, gSampling, contextSize, itos, \u001b[39m20\u001b[39;49m, maxSampleLength)\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m samples:\n\u001b[0;32m      3\u001b[0m     logSimple(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(s\u001b[39m.\u001b[39mvalues)\u001b[39m:\u001b[39;00m\u001b[39m<21\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00m(s\u001b[39m.\u001b[39mprob\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m10000\u001b[39m)\u001b[39m:\u001b[39;00m\u001b[39m>4.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\m.minich\\Desktop\\Moje\\makemore-mm\\projects\\layers\\neural.py:75\u001b[0m, in \u001b[0;36msampleMany2\u001b[1;34m(np, g, contextSize, itos, countSamples, maxSampleLength)\u001b[0m\n\u001b[0;32m     73\u001b[0m samples: \u001b[39mlist\u001b[39m[Sample] \u001b[39m=\u001b[39m []\n\u001b[0;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(countSamples):\n\u001b[1;32m---> 75\u001b[0m     s \u001b[39m=\u001b[39m sampleOne2(np, g, contextSize, itos, maxSampleLength)\n\u001b[0;32m     76\u001b[0m     \u001b[39mif\u001b[39;00m s \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m.minich\\Desktop\\Moje\\makemore-mm\\projects\\layers\\neural.py:103\u001b[0m, in \u001b[0;36msampleOne2\u001b[1;34m(np, g, contextSize, itos, maxLength)\u001b[0m\n\u001b[0;32m    101\u001b[0m s\u001b[39m.\u001b[39mprobs\u001b[39m.\u001b[39mappend(probs[\u001b[39m0\u001b[39m, ix]\u001b[39m.\u001b[39mitem())\n\u001b[0;32m    102\u001b[0m context \u001b[39m=\u001b[39m context[\u001b[39m1\u001b[39m:] \u001b[39m+\u001b[39m [ix]\n\u001b[1;32m--> 103\u001b[0m s\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mappend(itos[ix])\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m ix \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \n\u001b[0;32m    105\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 190"
     ]
    }
   ],
   "source": [
    "samples = sampleMany2(np2, gSampling, contextSize, itos, 20, maxSampleLength)\n",
    "for s in samples:\n",
    "    logSimple(f\"{''.join(s.values):<21}{(s.prob * 10000):>4.0f}: \", end=\"\")\n",
    "    for p in s.probs:\n",
    "        logSimple(f\"{(p / (1 / 27) * 10):.0f} \", end=\"\")\n",
    "    logSimple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    def printProb(txt: str):\n",
    "        ps = calcProb(np, cal, txt, contextSize, stoi)\n",
    "        op = calcOneProb(ps)\n",
    "        logSimple(f\"{txt:<21}{(op * 10000):<7.0f}: \", end=\"\")\n",
    "        for p in ps:\n",
    "            logSimple(f\"{(p / (1 / 27) * 10):.0f} \", end=\"\")\n",
    "        logSimple()\n",
    "\n",
    "    printProb('.')\n",
    "    printProb('m.')\n",
    "    printProb('mi.')\n",
    "    printProb('mic.')\n",
    "    printProb('mich.')\n",
    "    printProb('micha.')\n",
    "    printProb('michal.')\n",
    "    printProb('michael.')\n",
    "    printProb('michaela.')\n",
    "    printProb('michaella.')\n",
    "    printProb('michel.')\n",
    "    printProb('michalx.')\n",
    "    printProb('michalxx.')\n",
    "    printProb('michalxxx.')\n",
    "    printProb('martin.')\n",
    "    printProb('andrej.')\n",
    "    printProb('andrey.')\n",
    "    printProb('joey.')\n",
    "    printProb('james.')\n",
    "    printProb('xin.')\n",
    "    printProb('maxim.')\n",
    "    printProb('alex.')\n",
    "    printProb('alexa.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    plt.plot(range(len(lrAtIx)), lrAtIx, \"black\")\n",
    "    plt.ylim(min(lrAtIx), max(lrAtIx))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    print(\"Actual min max LR\", max(lrAtIx), min(lrAtIx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(fr.h.abs() > 0.99, cmap=\"gray\", interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    ax.set_facecolor(\"#222222\")\n",
    "    #ax.plot(lrAtIx, lossAtIx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    ax.set_facecolor(\"#222222\")\n",
    "    ax.plot(stepIx, lossAtIx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    ax.set_facecolor(\"#222222\")\n",
    "    ax.plot(stepIx, logLossAtIx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    dim = 0\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    sc = plt.scatter(np.C[:, dim].data, np.C[:,dim + 1].data, s=200)\n",
    "    for i in range(np.C.shape[0]):\n",
    "        plt.text(np.C[i, dim].item(), np.C[i, dim + 1].item(), itos[i], ha=\"center\", va=\"center\", color=\"white\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.C.shape, trX.shape, np.C[trX].shape, np.C[:5], trX[:5], np.C[trX][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8774, -0.6801], [0.8774, -0.6801], [0.8774, -0.6801]]\n",
      "[[0.8774, -0.6801], [0.8774, -0.6801], [0.0965, -0.5708]]\n",
      "[[0.8774, -0.6801], [0.0965, -0.5708], [0.218, -0.382]]\n",
      "[[0.0965, -0.5708], [0.218, -0.382], [-0.5288, 0.7074]]\n",
      "[[0.218, -0.382], [-0.5288, 0.7074], [-0.3088, 0.9816]]\n"
     ]
    }
   ],
   "source": [
    "# Let\"s suppose these are your lists\n",
    "C = [\n",
    "[ 0.8774, -0.6801],\n",
    "         [ 0.1651, -0.5025],\n",
    "         [ 0.2769, -0.3570],\n",
    "         [-0.8820,  0.3902],\n",
    "         [-0.4824,  0.8744],\n",
    "         [-0.3190,  0.7807],\n",
    "         [-0.0100, -0.3401],\n",
    "         [ 0.9975,  2.8280],\n",
    "         [ 0.9623, -1.3172],\n",
    "         [ 0.2180, -0.3820],\n",
    "         [ 0.6139, -0.4287],\n",
    "         [-0.7386,  0.5880],\n",
    "         [-0.3088,  0.9816],\n",
    "         [ 0.3907, -0.4174],\n",
    "         [-0.7380,  0.5205],\n",
    "         [-0.5288,  0.7074],\n",
    "         [-0.3956,  0.9625],\n",
    "         [-0.3802, -0.3504],\n",
    "         [-0.2861,  0.7589],\n",
    "         [ 0.5309, -0.5105],\n",
    "         [-0.0922, -0.6410],\n",
    "         [-0.3823,  0.9899],\n",
    "         [ 0.0965, -0.5708],\n",
    "         [-0.8582, -1.3429],\n",
    "         [-0.4960,  0.2842],\n",
    "         [-0.6105,  0.1336],\n",
    "         [-0.2623,  0.2942]\n",
    "]\n",
    "trX = [\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 22],\n",
    "    [0, 22, 9],\n",
    "    [22, 9, 15],\n",
    "    [9, 15, 12],\n",
    "    # ... More values\n",
    "]\n",
    "\n",
    "# We create a new list to hold the result\n",
    "result = []\n",
    "\n",
    "# We loop over each element in trX\n",
    "for i in range(len(trX)):\n",
    "    temp = []\n",
    "    # Then we loop over each value in the element\n",
    "    for j in range(len(trX[i])):\n",
    "        # We use the value as an index to get the corresponding data from C\n",
    "        temp.append(C[trX[i][j]])\n",
    "    # We add the result to our new list\n",
    "    result.append(temp)\n",
    "\n",
    "# Let\"s log the first 5 elements of the result list\n",
    "for i in range(5):\n",
    "    print(result[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
