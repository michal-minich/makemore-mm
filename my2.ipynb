{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from datetime import datetime\n",
    "import math\n",
    "import random\n",
    "from mynn import *\n",
    "import numpy as NP\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common init:         -------------------------- 2023-07-13 18:05:48\n",
      "dtype:               torch.float32\n",
      "device:              cpu\n",
      "contextSize:         3\n",
      "newNet:              True\n"
     ]
    }
   ],
   "source": [
    "initLogging(\"Common init\")\n",
    "\n",
    "dtype = torch.float\n",
    "log(\"dtype\", dtype)\n",
    "\n",
    "dvc = torch.device(\"cpu\")\n",
    "log(\"device\", dvc.type)\n",
    "\n",
    "contextSize = 3\n",
    "log(\"contextSize\", contextSize)\n",
    "\n",
    "newNet = True\n",
    "log(\"newNet\", newNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data:        -------------------------- 2023-07-13 18:05:48\n",
      "filePath:            names.txt\n",
      "trRatio:             0.8\n",
      "devRatio:            0.9\n",
      "wordShufflingSeed:   42\n",
      "first few words:     ['yuheng', 'diondre', 'xavien', 'jori', 'juanluis']\n",
      "lenWords:            32033\n",
      "allPossibleChars:    ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "stoi:                {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "itos:                {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "vocabularyLength:    27\n",
      "data random probability: 3.2958\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Prepare data\")\n",
    "\n",
    "filePath = \"names.txt\"\n",
    "log(\"filePath\", filePath)\n",
    "\n",
    "trRatio = 0.8\n",
    "log(\"trRatio\", trRatio)\n",
    "\n",
    "devRatio = 0.9\n",
    "log(\"devRatio\", devRatio)\n",
    "\n",
    "wordShufflingSeed = 42\n",
    "log(\"wordShufflingSeed\", wordShufflingSeed)\n",
    "\n",
    "words = readFileSplitByLine(filePath)\n",
    "random.seed(wordShufflingSeed)\n",
    "random.shuffle(words)\n",
    "log(\"first few words\", words[:5])\n",
    "\n",
    "lenWords = len(words);\n",
    "log(\"lenWords\", lenWords)\n",
    "\n",
    "allPossibleChars = sorted(list(set(\"\".join(words))))\n",
    "log(\"allPossibleChars\", allPossibleChars)\n",
    "\n",
    "stoi = sToI(allPossibleChars)\n",
    "log(\"stoi\", stoi)\n",
    "\n",
    "itos = iToS(stoi)\n",
    "log(\"itos\", itos)\n",
    "\n",
    "vocabularyLength = len(itos)\n",
    "log(\"vocabularyLength\", vocabularyLength)\n",
    "\n",
    "log(\"data random probability\", f\"{-torch.tensor(1 / vocabularyLength).log().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare dataset:     -------------------------- 2023-07-13 18:05:48\n",
      "data dtype:          torch.int64\n",
      "data set training:   25626 torch.Size([182625, 3]) torch.Size([182625]) ['yuheng', 'diondre', 'xavien']\n",
      "data set validation: 3203 torch.Size([22655, 3]) torch.Size([22655]) ['amay', 'aytana', 'jenevi']\n",
      "data set test:       3204 torch.Size([22866, 3]) torch.Size([22866]) ['mustafa', 'reuben', 'kahlel']\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Prepare dataset\")\n",
    "\n",
    "dataDtype = torch.int64\n",
    "log(\"data dtype\", dataDtype)\n",
    "\n",
    "lenTrain = int(trRatio * lenWords)\n",
    "trWords = words[:lenTrain]\n",
    "trX, trY = buildDataSet(trWords, contextSize, stoi, itos, dataDtype, dvc)\n",
    "log(\"data set training\", lenTrain, trX.shape, trY.shape, trWords[:3])\n",
    "\n",
    "endVal = int(devRatio * lenWords)\n",
    "valWords = words[lenTrain:endVal];\n",
    "valX, valY = buildDataSet(valWords, contextSize, stoi, itos, dataDtype, dvc)\n",
    "log(\"data set validation\", endVal - lenTrain, valX.shape, valY.shape, valWords[:3])\n",
    "\n",
    "lenTest = lenWords - endVal\n",
    "tstWords = words[endVal:]\n",
    "tstX, tstY = buildDataSet(tstWords, contextSize, stoi, itos, dataDtype, dvc)\n",
    "log(\"data set test\", lenTest, tstX.shape, tstY.shape, tstWords[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build network:       -------------------------- 2023-07-13 18:05:49\n",
      "embeddingDims:       10\n",
      "hiddenLayerSize:     100\n",
      "learningSeed:        2147483647\n",
      "Network Structure:  \n",
      "Layer LinearWithBias 4: torch.Size([30, 100]), torch.Size([100]), \n",
      "Layer Tanh 5: \n",
      "Layer LinearWithBias 6: torch.Size([100, 100]), torch.Size([100]), \n",
      "Parameters Count:    13470\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Build network\")\n",
    "\n",
    "embeddingDims = 10\n",
    "log(\"embeddingDims\", embeddingDims)\n",
    "\n",
    "hiddenLayerSize = 100\n",
    "log(\"hiddenLayerSize\", hiddenLayerSize)\n",
    "\n",
    "learningSeed = 2147483647\n",
    "log(\"learningSeed\", learningSeed)\n",
    "g = torch.Generator(device=dvc).manual_seed(learningSeed)\n",
    "\n",
    "if newNet:\n",
    "    np2 = makeNetwork2(g, vocabularyLength, embeddingDims, contextSize, hiddenLayerSize, dtype, dvc)\n",
    "    printNetwork(np2)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def trLoss2(): return getLoss2(np2, np2.C[trX], trY)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def valLoss2(): return getLoss2(np2, np2.C[valX], valY)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def tstLoss2(): return getLoss2(np2, np2.C[tstX], tstY)\n",
    "\n",
    "    def getLosses2() -> Losses2:\n",
    "        l = Losses2()\n",
    "        l.tr = trLoss2()\n",
    "        l.val = valLoss2()\n",
    "        l.tst = tstLoss2()\n",
    "        return l\n",
    "\n",
    "    def logLosses2():\n",
    "        losses = getLosses2()\n",
    "        l1 = f\"{losses.tr.loss.item():>10.4f}\"\n",
    "        l2 = f\"{losses.val.loss.item():>10.4f}\"\n",
    "        l3 = f\"{losses.tst.loss.item():>10.4f}\"\n",
    "        logSimple(f\"{l1} {l2} {l3}\")\n",
    "else :\n",
    "    np = makeNetwork(g, vocabularyLength, embeddingDims, contextSize, hiddenLayerSize, dvc)\n",
    "    log(\"parametersCount\", sum(p.nelement() for p in np.all))\n",
    "\n",
    "    cal = calibrateBatchNorm(np, trX)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(cal.mean.tolist(), 100)\n",
    "    plt.title(\"Calibration: mean of pre-activations\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(cal.std.tolist(), 100)\n",
    "    plt.title(\"Calibration: standard deviation of pre-activations\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def trLoss(): return getLoss(np, cal, np.C[trX], trY)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def valLoss(): return getLoss(np, cal, np.C[valX], valY)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def tstLoss(): return getLoss(np, cal, np.C[tstX], tstY)\n",
    "\n",
    "    def getLosses() -> Losses:\n",
    "        l = Losses()\n",
    "        l.tr = trLoss()\n",
    "        l.val = valLoss()\n",
    "        l.tst = tstLoss()\n",
    "        return l\n",
    "\n",
    "    def logLosses():\n",
    "        losses = getLosses()\n",
    "        l1 = f\"{losses.tr.loss.item():>10.4f}\"\n",
    "        l2 = f\"{losses.val.loss.item():>10.4f}\"\n",
    "        l3 = f\"{losses.tst.loss.item():>10.4f}\"\n",
    "        logSimple(f\"{l1} {l2} {l3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning:            -------------------------- 2023-07-13 18:05:49\n",
      "trainingBatchSize:   32\n",
      "trainingSteps: :     5708\n",
      "maxIteration:        200000\n",
      "repeats:             36\n",
      "maxLr:               0.14\n",
      "minLr:               0.0001\n",
      "actualIterations:    200000\n",
      "  0,      0 losses:     0.0000       4.5749     4.5745     4.5742\n",
      "  1,   5708 losses:     2.4943       2.3476     2.3441     2.3473\n",
      "  2,  11416 losses:     2.3216       2.2889     2.2911     2.2899\n",
      "  3,  17124 losses:     2.1395       2.2628     2.2645     2.2653\n",
      "  4,  22832 losses:     2.5993       2.2338     2.2428     2.2413\n",
      "  5,  28540 losses:     2.1791       2.2145     2.2250     2.2245\n",
      "  6,  34248 losses:     2.1214       2.2146     2.2204     2.2234\n",
      "  7,  39956 losses:     2.1114       2.1987     2.2123     2.2098\n",
      "  8,  45664 losses:     1.9537       2.1914     2.2064     2.2045\n",
      "  9,  51372 losses:     2.1421       2.1940     2.2042     2.2127\n",
      " 10,  57080 losses:     2.1321       2.1771     2.1920     2.1953\n",
      " 11,  62788 losses:     2.3595       2.1781     2.1947     2.2019\n",
      " 12,  68496 losses:     1.8229       2.1735     2.1930     2.1987\n",
      " 13,  74204 losses:     1.8845       2.1741     2.1955     2.1960\n",
      " 14,  79912 losses:     1.7939       2.1651     2.1890     2.1896\n",
      " 15,  85620 losses:     2.1973       2.1626     2.1807     2.1856\n",
      " 16,  91328 losses:     2.1765       2.1587     2.1758     2.1838\n",
      " 17,  97036 losses:     2.1633       2.1461     2.1689     2.1723\n",
      " 18, 102744 losses:     2.4814       2.1482     2.1696     2.1765\n",
      " 19, 108452 losses:     1.8648       2.1438     2.1656     2.1716\n",
      " 20, 114160 losses:     2.2500       2.1357     2.1572     2.1646\n",
      " 21, 119868 losses:     1.9024       2.1364     2.1607     2.1654\n",
      " 22, 125576 losses:     2.2363       2.1329     2.1618     2.1636\n",
      " 23, 131284 losses:     2.3785       2.1295     2.1564     2.1595\n",
      " 24, 136992 losses:     1.9560       2.1246     2.1529     2.1588\n",
      " 25, 142700 losses:     2.1184       2.1202     2.1462     2.1527\n",
      " 26, 148408 losses:     1.7462       2.1173     2.1447     2.1506\n",
      " 27, 154116 losses:     2.0148       2.1178     2.1461     2.1518\n",
      " 28, 159824 losses:     2.3460       2.1152     2.1444     2.1495\n",
      " 29, 165532 losses:     2.1111       2.1113     2.1430     2.1462\n",
      " 30, 171240 losses:     2.0429       2.1062     2.1365     2.1433\n",
      " 31, 176948 losses:     2.3268       2.1073     2.1360     2.1439\n",
      " 32, 182656 losses:     2.1541       2.1032     2.1329     2.1397\n",
      " 33, 188364 losses:     1.9206       2.1001     2.1305     2.1367\n",
      " 34, 194072 losses:     2.2141       2.0978     2.1283     2.1345\n",
      " 35, 199780 losses:     1.6535       2.0962     2.1275     2.1326\n",
      "Break at max iteration:\n",
      " final losses:          1.9525       2.0962     2.1275     2.1326\n",
      "emb.shape:           torch.Size([32, 3, 10])\n",
      "logits.shape:        torch.Size([32, 100])\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Learning\")\n",
    "\n",
    "trainingBatchSize = 32\n",
    "log(\"trainingBatchSize\", trainingBatchSize)\n",
    "\n",
    "trXLength = trX.shape[0]\n",
    "trainingSteps = (trXLength // trainingBatchSize) + 1\n",
    "log (\"trainingSteps: \", trainingSteps)\n",
    "\n",
    "maxIteration = 200_000\n",
    "log(\"maxIteration\", maxIteration)\n",
    "\n",
    "repeats = 36\n",
    "log(\"repeats\",repeats)\n",
    "\n",
    "maxLr = 0.14\n",
    "log(\"maxLr\", maxLr)\n",
    "\n",
    "minLr = 0.0001\n",
    "log(\"minLr\", minLr)\n",
    "\n",
    "actualIterations = min(maxIteration, repeats * math.ceil(trXLength / trainingBatchSize))\n",
    "log(\"actualIterations\", actualIterations)\n",
    "\n",
    "lrAtIx: list[float] = []\n",
    "stepIx: list[int] = []\n",
    "lossAtIx: list[float] = []\n",
    "logLossAtIx: list[float] = []\n",
    "up = UpdateNetResult()\n",
    "fr = ForwardPassResult()\n",
    "fr.loss = torch.tensor(0)\n",
    "i = 0\n",
    "\n",
    "if newNet:\n",
    "    bnMeanRunning = 0\n",
    "    bnStdRunning = 0\n",
    "    for repeat in range(repeats):\n",
    "        \n",
    "        if i >= maxIteration:\n",
    "            break;\n",
    "\n",
    "        logSimple(f\"{repeat:>3}, {i:>6} losses: {fr.loss.item():>10.4f}   \", end=\"\")\n",
    "        logLosses2()\n",
    "\n",
    "        for start in range(0, trXLength, trainingBatchSize):\n",
    "\n",
    "            if i >= maxIteration:\n",
    "                log(\"Break at max iteration\")\n",
    "                break;\n",
    "            \n",
    "            end = min(start + trainingBatchSize, trXLength)\n",
    "            miniBatchIxs = torch.randint(0, trXLength, (trainingBatchSize,), generator=g, device=dvc)\n",
    "            fr = forwardPass2(np2, trX, trY, miniBatchIxs)\n",
    "            backwardPass2(np2.layers, np2.parameters, fr.loss)\n",
    "\n",
    "            up = updateNet(np2.parameters, i, actualIterations, maxLr, minLr)\n",
    "            lrAtIx.append(up.learningRate)\n",
    "\n",
    "            stepIx.append(i)\n",
    "            lossAtIx.append(fr.loss.item())\n",
    "            logLossAtIx.append(fr.loss.log10().item())\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    logSimple(f\" final losses: {fr.loss.item():>15.4f}   \", end=\"\")\n",
    "    logLosses2()\n",
    "else:\n",
    "    lr = 0.1;\n",
    "    lre = torch.linspace(-3, 0, trainingSteps)\n",
    "    lrs = 10 ** lre\n",
    "\n",
    "    for repeat in range(repeats):\n",
    "        \n",
    "        if i >= maxIteration:\n",
    "            break;\n",
    "\n",
    "        logSimple(f\"{repeat:>3}, {i:>6} losses: {fr.loss.item():>10.4f}   \", end=\"\")\n",
    "        logLosses()\n",
    "\n",
    "        for start in range(0, trXLength, trainingBatchSize):\n",
    "\n",
    "            if i >= maxIteration:\n",
    "                log(\"Break at max iteration\")\n",
    "                break;\n",
    "            \n",
    "            end = min(start + trainingBatchSize, trXLength)\n",
    "            #miniBatchIxs = torch.arange(start, end)\n",
    "            miniBatchIxs = torch.randint(0, trXLength, (trainingBatchSize,), generator=g, device=dvc)\n",
    "            fr = forwardPass(np, cal, trX, trY, miniBatchIxs)\n",
    "            backwardPass(np.all, fr.loss)\n",
    "\n",
    "            if i == 1:\n",
    "                plt.figure(figsize=(20, 10))\n",
    "                plt.imshow(fr.h.abs() > 0.99, cmap=\"gray\", interpolation=\"nearest\")\n",
    "                \n",
    "                plt.figure()\n",
    "                plt.hist(fr.h.view(-1).tolist(), 100)\n",
    "                plt.title('Histogram of h')\n",
    "\n",
    "                plt.figure()\n",
    "                plt.hist(fr.hPreActivations.view(-1).tolist(), 100)\n",
    "                plt.title('Histogram of hPreActivations')\n",
    "\n",
    "                plt.figure()\n",
    "                plt.hist(fr.hPreActivations.mean(0, keepdim=True).view(-1).tolist(), 100)\n",
    "                plt.title('Histogram of Mean of hPreActivations')\n",
    "\n",
    "                plt.figure()\n",
    "                plt.hist(fr.hPreActivations.std(0, keepdim=True).view(-1).tolist(), 100)\n",
    "                plt.title('Histogram of Std of hPreActivations')\n",
    "\n",
    "            up = updateNet(np.all, i, actualIterations, maxLr, minLr)\n",
    "            lrAtIx.append(up.learningRate)\n",
    "\n",
    "            stepIx.append(i)\n",
    "            lossAtIx.append(fr.loss.item())\n",
    "            logLossAtIx.append(fr.loss.log10().item())\n",
    "\n",
    "            #lr = lrs[i].item()\n",
    "            #lrAtIx.append(lrs[i].item())\n",
    "            \n",
    "            i += 1\n",
    "    \n",
    "    logSimple(f\" final losses: {fr.loss.item():>15.4f}   \", end=\"\")\n",
    "    logLosses()\n",
    "\n",
    "#bestLr = lrs[findLowestIndex(lossAtIx)].item();\n",
    "#log(\"best learning rate\", bestLr)\n",
    "log(\"emb.shape\", fr.emb.shape)\n",
    "#log(\"h.shape\", fr.h.shape)\n",
    "log(\"logits.shape\", fr.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling:            -------------------------- 2023-07-13 18:08:25\n",
      "samplingSeed:        2147483657\n",
      "maxSampleLength:     50\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Sampling\")\n",
    "\n",
    "samplingSeed = learningSeed + 10\n",
    "gSampling = torch.Generator(device=dvc).manual_seed(samplingSeed)\n",
    "log(\"samplingSeed\", samplingSeed)\n",
    "\n",
    "maxSampleLength = 50\n",
    "log(\"maxSampleLength\", maxSampleLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mona.                 193: 20 19 86 20 171 \n",
      "kayah.                328: 25 112 44 35 66 253 \n",
      "seel.                 108: 18 24 5 42 125 \n",
      "ndyn.                  41: 10 1 12 66 216 \n",
      "alee.                 506: 38 40 75 59 180 \n",
      "threttedraegus.        51: 11 23 18 58 15 106 86 1 46 56 19 8 57 111 83 \n",
      "ched.                  78: 12 61 39 4 79 \n",
      "elin.                 198: 13 85 94 52 126 \n",
      "shi.                  161: 18 53 30 43 \n",
      "jenrene.              142: 21 46 77 6 54 59 13 126 \n",
      "susopharleiyah.       130: 18 18 23 12 18 209 43 29 58 108 30 8 237 113 253 \n",
      "hotelin.               40: 7 26 2 22 44 51 52 126 \n",
      "shub.                  76: 18 53 7 2 155 \n",
      "ridhiraes.             55: 14 36 28 4 30 24 117 4 20 44 \n",
      "kindreelynn.          230: 25 24 104 19 43 75 40 34 34 175 117 225 \n",
      "novana.               106: 10 38 54 106 146 18 155 \n",
      "ubrence.                6: 1 13 117 78 72 10 193 139 \n",
      "ryamili.               97: 14 20 64 16 96 64 57 23 \n",
      "eli.                  153: 13 85 94 22 \n",
      "kay.                  228: 25 112 44 15 \n"
     ]
    }
   ],
   "source": [
    "if newNet:\n",
    "    samples = sampleMany2(np2, gSampling, contextSize, itos, 20, maxSampleLength)\n",
    "    for s in samples:\n",
    "        logSimple(f\"{''.join(s.values):<21}{(s.prob * 10000):>4.0f}: \", end=\"\")\n",
    "        for p in s.probs:\n",
    "            logSimple(f\"{(p / (1 / 27) * 10):.0f} \", end=\"\")\n",
    "        logSimple()\n",
    "else:\n",
    "    samples = sampleMany(np, cal, gSampling, contextSize, itos, 20, maxSampleLength)\n",
    "    for s in samples:\n",
    "        logSimple(f\"{''.join(s.values):<21}{(s.prob * 10000):>4.0f}: \", end=\"\")\n",
    "        for p in s.probs:\n",
    "            logSimple(f\"{(p / (1 / 27) * 10):.0f} \", end=\"\")\n",
    "        logSimple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    def printProb(txt: str):\n",
    "        ps = calcProb(np, cal, txt, contextSize, stoi)\n",
    "        op = calcOneProb(ps)\n",
    "        logSimple(f\"{txt:<21}{(op * 10000):<7.0f}: \", end=\"\")\n",
    "        for p in ps:\n",
    "            logSimple(f\"{(p / (1 / 27) * 10):.0f} \", end=\"\")\n",
    "        logSimple()\n",
    "\n",
    "    printProb('.')\n",
    "    printProb('m.')\n",
    "    printProb('mi.')\n",
    "    printProb('mic.')\n",
    "    printProb('mich.')\n",
    "    printProb('micha.')\n",
    "    printProb('michal.')\n",
    "    printProb('michael.')\n",
    "    printProb('michaela.')\n",
    "    printProb('michaella.')\n",
    "    printProb('michel.')\n",
    "    printProb('michalx.')\n",
    "    printProb('michalxx.')\n",
    "    printProb('michalxxx.')\n",
    "    printProb('martin.')\n",
    "    printProb('andrej.')\n",
    "    printProb('andrey.')\n",
    "    printProb('joey.')\n",
    "    printProb('james.')\n",
    "    printProb('xin.')\n",
    "    printProb('maxim.')\n",
    "    printProb('alex.')\n",
    "    printProb('alexa.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    plt.plot(range(len(lrAtIx)), lrAtIx, \"black\")\n",
    "    plt.ylim(min(lrAtIx), max(lrAtIx))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    print(\"Actual min max LR\", max(lrAtIx), min(lrAtIx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(fr.h.abs() > 0.99, cmap=\"gray\", interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    ax.set_facecolor(\"#222222\")\n",
    "    #ax.plot(lrAtIx, lossAtIx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    ax.set_facecolor(\"#222222\")\n",
    "    ax.plot(stepIx, lossAtIx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    ax.set_facecolor(\"#222222\")\n",
    "    ax.plot(stepIx, logLossAtIx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    dim = 0\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    sc = plt.scatter(np.C[:, dim].data, np.C[:,dim + 1].data, s=200)\n",
    "    for i in range(np.C.shape[0]):\n",
    "        plt.text(np.C[i, dim].item(), np.C[i, dim + 1].item(), itos[i], ha=\"center\", va=\"center\", color=\"white\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.C.shape, trX.shape, np.C[trX].shape, np.C[:5], trX[:5], np.C[trX][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8774, -0.6801], [0.8774, -0.6801], [0.8774, -0.6801]]\n",
      "[[0.8774, -0.6801], [0.8774, -0.6801], [0.0965, -0.5708]]\n",
      "[[0.8774, -0.6801], [0.0965, -0.5708], [0.218, -0.382]]\n",
      "[[0.0965, -0.5708], [0.218, -0.382], [-0.5288, 0.7074]]\n",
      "[[0.218, -0.382], [-0.5288, 0.7074], [-0.3088, 0.9816]]\n"
     ]
    }
   ],
   "source": [
    "# Let\"s suppose these are your lists\n",
    "C = [\n",
    "[ 0.8774, -0.6801],\n",
    "         [ 0.1651, -0.5025],\n",
    "         [ 0.2769, -0.3570],\n",
    "         [-0.8820,  0.3902],\n",
    "         [-0.4824,  0.8744],\n",
    "         [-0.3190,  0.7807],\n",
    "         [-0.0100, -0.3401],\n",
    "         [ 0.9975,  2.8280],\n",
    "         [ 0.9623, -1.3172],\n",
    "         [ 0.2180, -0.3820],\n",
    "         [ 0.6139, -0.4287],\n",
    "         [-0.7386,  0.5880],\n",
    "         [-0.3088,  0.9816],\n",
    "         [ 0.3907, -0.4174],\n",
    "         [-0.7380,  0.5205],\n",
    "         [-0.5288,  0.7074],\n",
    "         [-0.3956,  0.9625],\n",
    "         [-0.3802, -0.3504],\n",
    "         [-0.2861,  0.7589],\n",
    "         [ 0.5309, -0.5105],\n",
    "         [-0.0922, -0.6410],\n",
    "         [-0.3823,  0.9899],\n",
    "         [ 0.0965, -0.5708],\n",
    "         [-0.8582, -1.3429],\n",
    "         [-0.4960,  0.2842],\n",
    "         [-0.6105,  0.1336],\n",
    "         [-0.2623,  0.2942]\n",
    "]\n",
    "trX = [\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 22],\n",
    "    [0, 22, 9],\n",
    "    [22, 9, 15],\n",
    "    [9, 15, 12],\n",
    "    # ... More values\n",
    "]\n",
    "\n",
    "# We create a new list to hold the result\n",
    "result = []\n",
    "\n",
    "# We loop over each element in trX\n",
    "for i in range(len(trX)):\n",
    "    temp = []\n",
    "    # Then we loop over each value in the element\n",
    "    for j in range(len(trX[i])):\n",
    "        # We use the value as an index to get the corresponding data from C\n",
    "        temp.append(C[trX[i][j]])\n",
    "    # We add the result to our new list\n",
    "    result.append(temp)\n",
    "\n",
    "# Let\"s log the first 5 elements of the result list\n",
    "for i in range(5):\n",
    "    print(result[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
