{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from datetime import datetime\n",
    "import math\n",
    "import random\n",
    "import numpy as NP\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mm.printing import *\n",
    "from mm.neural.neural import *\n",
    "from mm.neural.introspection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common init:         -------------------------- 2023-07-14 14:29:54\n",
      "dtype:               torch.float32\n",
      "device:              cpu\n",
      "contextSize:         3\n",
      "newNet:              True\n"
     ]
    }
   ],
   "source": [
    "initLogging(\"Common init\")\n",
    "\n",
    "dtype = torch.float\n",
    "log(\"dtype\", dtype)\n",
    "\n",
    "dvc = torch.device(\"cpu\")\n",
    "log(\"device\", dvc.type)\n",
    "\n",
    "contextSize = 3\n",
    "log(\"contextSize\", contextSize)\n",
    "\n",
    "newNet = True\n",
    "log(\"newNet\", newNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data:        -------------------------- 2023-07-14 14:30:06\n",
      "filePath:            data/names.txt\n",
      "trRatio:             0.8\n",
      "devRatio:            0.9\n",
      "wordShufflingSeed:   42\n",
      "first few words:     ['yuheng', 'diondre', 'xavien', 'jori', 'juanluis']\n",
      "lenWords:            32033\n",
      "allPossibleChars:    ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "stoi:                {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "itos:                {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "vocabularyLength:    27\n",
      "data random probability: 3.2958\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Prepare data\")\n",
    "\n",
    "filePath = \"data/names.txt\"\n",
    "log(\"filePath\", filePath)\n",
    "\n",
    "trRatio = 0.8\n",
    "log(\"trRatio\", trRatio)\n",
    "\n",
    "devRatio = 0.9\n",
    "log(\"devRatio\", devRatio)\n",
    "\n",
    "wordShufflingSeed = 42\n",
    "log(\"wordShufflingSeed\", wordShufflingSeed)\n",
    "\n",
    "words = readFileSplitByLine(filePath)\n",
    "random.seed(wordShufflingSeed)\n",
    "random.shuffle(words)\n",
    "log(\"first few words\", words[:5])\n",
    "\n",
    "lenWords = len(words);\n",
    "log(\"lenWords\", lenWords)\n",
    "\n",
    "allPossibleChars = sorted(list(set(\"\".join(words))))\n",
    "log(\"allPossibleChars\", allPossibleChars)\n",
    "\n",
    "stoi = sToI(allPossibleChars)\n",
    "log(\"stoi\", stoi)\n",
    "\n",
    "itos = iToS(stoi)\n",
    "log(\"itos\", itos)\n",
    "\n",
    "vocabularyLength = len(itos)\n",
    "log(\"vocabularyLength\", vocabularyLength)\n",
    "\n",
    "log(\"data random probability\", f\"{-torch.tensor(1 / vocabularyLength).log().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare dataset:     -------------------------- 2023-07-14 14:30:09\n",
      "data dtype:          torch.int64\n",
      "data set training:   25626 torch.Size([182625, 3]) torch.Size([182625]) ['yuheng', 'diondre', 'xavien']\n",
      "data set validation: 3203 torch.Size([22655, 3]) torch.Size([22655]) ['amay', 'aytana', 'jenevi']\n",
      "data set test:       3204 torch.Size([22866, 3]) torch.Size([22866]) ['mustafa', 'reuben', 'kahlel']\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Prepare dataset\")\n",
    "\n",
    "dataDtype = torch.int64\n",
    "log(\"data dtype\", dataDtype)\n",
    "\n",
    "lenTrain = int(trRatio * lenWords)\n",
    "trWords = words[:lenTrain]\n",
    "trX, trY = buildDataSet(trWords, contextSize, stoi, itos, dataDtype, dvc)\n",
    "log(\"data set training\", lenTrain, trX.shape, trY.shape, trWords[:3])\n",
    "\n",
    "endVal = int(devRatio * lenWords)\n",
    "valWords = words[lenTrain:endVal];\n",
    "valX, valY = buildDataSet(valWords, contextSize, stoi, itos, dataDtype, dvc)\n",
    "log(\"data set validation\", endVal - lenTrain, valX.shape, valY.shape, valWords[:3])\n",
    "\n",
    "lenTest = lenWords - endVal\n",
    "tstWords = words[endVal:]\n",
    "tstX, tstY = buildDataSet(tstWords, contextSize, stoi, itos, dataDtype, dvc)\n",
    "log(\"data set test\", lenTest, tstX.shape, tstY.shape, tstWords[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build network:       -------------------------- 2023-07-14 14:30:13\n",
      "embeddingDims:       10\n",
      "hiddenLayerSize:     100\n",
      "learningSeed:        2147483647\n",
      "Network Structure:  \n",
      "Layer LinearWithBias 1: torch.Size([30, 100]), torch.Size([100]), \n",
      "Layer Tanh 2: \n",
      "Layer LinearWithBias 3: torch.Size([100, 100]), torch.Size([100]), \n",
      "Parameters Count:    13470\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Build network\")\n",
    "\n",
    "embeddingDims = 10\n",
    "log(\"embeddingDims\", embeddingDims)\n",
    "\n",
    "hiddenLayerSize = 100\n",
    "log(\"hiddenLayerSize\", hiddenLayerSize)\n",
    "\n",
    "learningSeed = 2147483647\n",
    "log(\"learningSeed\", learningSeed)\n",
    "g = torch.Generator(device=dvc).manual_seed(learningSeed)\n",
    "\n",
    "if newNet:\n",
    "    np2 = makeNetwork2(g, vocabularyLength, embeddingDims, contextSize, hiddenLayerSize, dtype, dvc)\n",
    "    printNetwork(np2)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def trLoss2(): return getLoss2(np2, np2.C[trX], trY)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def valLoss2(): return getLoss2(np2, np2.C[valX], valY)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def tstLoss2(): return getLoss2(np2, np2.C[tstX], tstY)\n",
    "\n",
    "    def getLosses2() -> Losses2:\n",
    "        l = Losses2()\n",
    "        l.tr = trLoss2()\n",
    "        l.val = valLoss2()\n",
    "        l.tst = tstLoss2()\n",
    "        return l\n",
    "\n",
    "    def logLosses2():\n",
    "        losses = getLosses2()\n",
    "        l1 = f\"{losses.tr.loss.item():>10.4f}\"\n",
    "        l2 = f\"{losses.val.loss.item():>10.4f}\"\n",
    "        l3 = f\"{losses.tst.loss.item():>10.4f}\"\n",
    "        logSimple(f\"{l1} {l2} {l3}\")\n",
    "else :\n",
    "    np = makeNetwork(g, vocabularyLength, embeddingDims, contextSize, hiddenLayerSize, dvc)\n",
    "    log(\"parametersCount\", sum(p.nelement() for p in np.all))\n",
    "\n",
    "    cal = calibrateBatchNorm(np, trX)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(cal.mean.tolist(), 100)\n",
    "    plt.title(\"Calibration: mean of pre-activations\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(cal.std.tolist(), 100)\n",
    "    plt.title(\"Calibration: standard deviation of pre-activations\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def trLoss(): return getLoss(np, cal, np.C[trX], trY)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def valLoss(): return getLoss(np, cal, np.C[valX], valY)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def tstLoss(): return getLoss(np, cal, np.C[tstX], tstY)\n",
    "\n",
    "    def getLosses() -> Losses:\n",
    "        l = Losses()\n",
    "        l.tr = trLoss()\n",
    "        l.val = valLoss()\n",
    "        l.tst = tstLoss()\n",
    "        return l\n",
    "\n",
    "    def logLosses():\n",
    "        losses = getLosses()\n",
    "        l1 = f\"{losses.tr.loss.item():>10.4f}\"\n",
    "        l2 = f\"{losses.val.loss.item():>10.4f}\"\n",
    "        l3 = f\"{losses.tst.loss.item():>10.4f}\"\n",
    "        logSimple(f\"{l1} {l2} {l3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning:            -------------------------- 2023-07-14 14:30:18\n",
      "trainingBatchSize:   32\n",
      "trainingSteps: :     5708\n",
      "maxIteration:        2000\n",
      "repeats:             36\n",
      "maxLr:               0.14\n",
      "minLr:               0.0001\n",
      "actualIterations:    2000\n",
      "  0,      0 losses:     0.0000       4.5749     4.5745     4.5742\n",
      "Break at max iteration:\n",
      " final losses:          2.8262       2.4965     2.4895     2.4940\n",
      "emb.shape:           torch.Size([32, 3, 10])\n",
      "logits.shape:        torch.Size([32, 100])\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Learning\")\n",
    "\n",
    "trainingBatchSize = 32\n",
    "log(\"trainingBatchSize\", trainingBatchSize)\n",
    "\n",
    "trXLength = trX.shape[0]\n",
    "trainingSteps = (trXLength // trainingBatchSize) + 1\n",
    "log (\"trainingSteps: \", trainingSteps)\n",
    "\n",
    "maxIteration = 2_000\n",
    "log(\"maxIteration\", maxIteration)\n",
    "\n",
    "repeats = 36\n",
    "log(\"repeats\",repeats)\n",
    "\n",
    "maxLr = 0.14\n",
    "log(\"maxLr\", maxLr)\n",
    "\n",
    "minLr = 0.0001\n",
    "log(\"minLr\", minLr)\n",
    "\n",
    "actualIterations = min(maxIteration, repeats * math.ceil(trXLength / trainingBatchSize))\n",
    "log(\"actualIterations\", actualIterations)\n",
    "\n",
    "lrAtIx: list[float] = []\n",
    "stepIx: list[int] = []\n",
    "lossAtIx: list[float] = []\n",
    "logLossAtIx: list[float] = []\n",
    "up = UpdateNetResult()\n",
    "fr = ForwardPassResult()\n",
    "fr.loss = torch.tensor(0)\n",
    "i = 0\n",
    "\n",
    "if newNet:\n",
    "    bnMeanRunning = 0\n",
    "    bnStdRunning = 0\n",
    "    for repeat in range(repeats):\n",
    "        \n",
    "        if i >= maxIteration:\n",
    "            break;\n",
    "\n",
    "        logSimple(f\"{repeat:>3}, {i:>6} losses: {fr.loss.item():>10.4f}   \", end=\"\")\n",
    "        logLosses2()\n",
    "\n",
    "        for start in range(0, trXLength, trainingBatchSize):\n",
    "\n",
    "            if i >= maxIteration:\n",
    "                log(\"Break at max iteration\")\n",
    "                break;\n",
    "            \n",
    "            end = min(start + trainingBatchSize, trXLength)\n",
    "            miniBatchIxs = torch.randint(0, trXLength, (trainingBatchSize,), generator=g, device=dvc)\n",
    "            fr = forwardPass2(np2, trX, trY, miniBatchIxs)\n",
    "            backwardPass2(np2.layers, np2.parameters, fr.loss)\n",
    "\n",
    "            up = updateNet(np2.parameters, i, actualIterations, maxLr, minLr)\n",
    "            lrAtIx.append(up.learningRate)\n",
    "\n",
    "            stepIx.append(i)\n",
    "            lossAtIx.append(fr.loss.item())\n",
    "            logLossAtIx.append(fr.loss.log10().item())\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    logSimple(f\" final losses: {fr.loss.item():>15.4f}   \", end=\"\")\n",
    "    logLosses2()\n",
    "else:\n",
    "    lr = 0.1;\n",
    "    lre = torch.linspace(-3, 0, trainingSteps)\n",
    "    lrs = 10 ** lre\n",
    "\n",
    "    for repeat in range(repeats):\n",
    "        \n",
    "        if i >= maxIteration:\n",
    "            break;\n",
    "\n",
    "        logSimple(f\"{repeat:>3}, {i:>6} losses: {fr.loss.item():>10.4f}   \", end=\"\")\n",
    "        logLosses()\n",
    "\n",
    "        for start in range(0, trXLength, trainingBatchSize):\n",
    "\n",
    "            if i >= maxIteration:\n",
    "                log(\"Break at max iteration\")\n",
    "                break;\n",
    "            \n",
    "            end = min(start + trainingBatchSize, trXLength)\n",
    "            #miniBatchIxs = torch.arange(start, end)\n",
    "            miniBatchIxs = torch.randint(0, trXLength, (trainingBatchSize,), generator=g, device=dvc)\n",
    "            fr = forwardPass(np, cal, trX, trY, miniBatchIxs)\n",
    "            backwardPass(np.all, fr.loss)\n",
    "\n",
    "            if i == 1:\n",
    "                plt.figure(figsize=(20, 10))\n",
    "                plt.imshow(fr.h.abs() > 0.99, cmap=\"gray\", interpolation=\"nearest\")\n",
    "                \n",
    "                plt.figure()\n",
    "                plt.hist(fr.h.view(-1).tolist(), 100)\n",
    "                plt.title('Histogram of h')\n",
    "\n",
    "                plt.figure()\n",
    "                plt.hist(fr.hPreActivations.view(-1).tolist(), 100)\n",
    "                plt.title('Histogram of hPreActivations')\n",
    "\n",
    "                plt.figure()\n",
    "                plt.hist(fr.hPreActivations.mean(0, keepdim=True).view(-1).tolist(), 100)\n",
    "                plt.title('Histogram of Mean of hPreActivations')\n",
    "\n",
    "                plt.figure()\n",
    "                plt.hist(fr.hPreActivations.std(0, keepdim=True).view(-1).tolist(), 100)\n",
    "                plt.title('Histogram of Std of hPreActivations')\n",
    "\n",
    "            up = updateNet(np.all, i, actualIterations, maxLr, minLr)\n",
    "            lrAtIx.append(up.learningRate)\n",
    "\n",
    "            stepIx.append(i)\n",
    "            lossAtIx.append(fr.loss.item())\n",
    "            logLossAtIx.append(fr.loss.log10().item())\n",
    "\n",
    "            #lr = lrs[i].item()\n",
    "            #lrAtIx.append(lrs[i].item())\n",
    "            \n",
    "            i += 1\n",
    "    \n",
    "    logSimple(f\" final losses: {fr.loss.item():>15.4f}   \", end=\"\")\n",
    "    logLosses()\n",
    "\n",
    "#bestLr = lrs[findLowestIndex(lossAtIx)].item();\n",
    "#log(\"best learning rate\", bestLr)\n",
    "log(\"emb.shape\", fr.emb.shape)\n",
    "#log(\"h.shape\", fr.h.shape)\n",
    "log(\"logits.shape\", fr.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling:            -------------------------- 2023-07-14 14:30:50\n",
      "samplingSeed:        2147483657\n",
      "maxSampleLength:     50\n"
     ]
    }
   ],
   "source": [
    "logSection(\"Sampling\")\n",
    "\n",
    "samplingSeed = learningSeed + 10\n",
    "gSampling = torch.Generator(device=dvc).manual_seed(samplingSeed)\n",
    "log(\"samplingSeed\", samplingSeed)\n",
    "\n",
    "maxSampleLength = 50\n",
    "log(\"maxSampleLength\", maxSampleLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scienig.               50: 17 4 21 25 53 12 2 63 \n",
      "atin.                 254: 38 8 35 25 133 \n",
      "aud.                  111: 38 6 10 13 \n",
      "aiwe.                 154: 38 11 2 39 100 \n",
      "dih.                   88: 12 34 11 87 \n",
      "vorle.                 28: 5 22 55 10 50 46 \n",
      "ajalenaneniatrelita.  150: 38 3 44 27 44 46 22 46 18 36 14 33 8 10 50 23 38 9 54 119 \n",
      "iia.                   38: 4 13 42 127 \n",
      "jilon.                154: 20 31 27 15 65 158 \n",
      "et.                    22: 11 7 2 \n",
      "jynn.                 106: 20 10 16 14 160 \n",
      "loryisoryinog.         39: 15 21 53 12 19 12 8 18 14 19 38 6 2 76 \n",
      "amaoriz.              133: 38 14 63 4 29 65 3 39 \n",
      "biyk.                  41: 10 28 14 2 87 \n",
      "ameciten.             166: 38 14 44 4 20 9 38 45 161 \n",
      "jare.                 209: 20 108 49 41 48 \n",
      "jien.                 188: 20 31 22 51 181 \n",
      "ama.                  297: 38 14 63 42 \n",
      "copen.                 60: 12 16 2 37 49 166 \n",
      "tyen.                  71: 9 11 27 53 174 \n"
     ]
    }
   ],
   "source": [
    "if newNet:\n",
    "    samples = sampleMany2(np2, gSampling, contextSize, itos, 20, maxSampleLength)\n",
    "    for s in samples:\n",
    "        logSimple(f\"{''.join(s.values):<21}{(s.prob * 10000):>4.0f}: \", end=\"\")\n",
    "        for p in s.probs:\n",
    "            logSimple(f\"{(p / (1 / 27) * 10):.0f} \", end=\"\")\n",
    "        logSimple()\n",
    "else:\n",
    "    samples = sampleMany(np, cal, gSampling, contextSize, itos, 20, maxSampleLength)\n",
    "    for s in samples:\n",
    "        logSimple(f\"{''.join(s.values):<21}{(s.prob * 10000):>4.0f}: \", end=\"\")\n",
    "        for p in s.probs:\n",
    "            logSimple(f\"{(p / (1 / 27) * 10):.0f} \", end=\"\")\n",
    "        logSimple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    def printProb(txt: str):\n",
    "        ps = calcProb(np, cal, txt, contextSize, stoi)\n",
    "        op = calcOneProb(ps)\n",
    "        logSimple(f\"{txt:<21}{(op * 10000):<7.0f}: \", end=\"\")\n",
    "        for p in ps:\n",
    "            logSimple(f\"{(p / (1 / 27) * 10):.0f} \", end=\"\")\n",
    "        logSimple()\n",
    "\n",
    "    printProb('.')\n",
    "    printProb('m.')\n",
    "    printProb('mi.')\n",
    "    printProb('mic.')\n",
    "    printProb('mich.')\n",
    "    printProb('micha.')\n",
    "    printProb('michal.')\n",
    "    printProb('michael.')\n",
    "    printProb('michaela.')\n",
    "    printProb('michaella.')\n",
    "    printProb('michel.')\n",
    "    printProb('michalx.')\n",
    "    printProb('michalxx.')\n",
    "    printProb('michalxxx.')\n",
    "    printProb('martin.')\n",
    "    printProb('andrej.')\n",
    "    printProb('andrey.')\n",
    "    printProb('joey.')\n",
    "    printProb('james.')\n",
    "    printProb('xin.')\n",
    "    printProb('maxim.')\n",
    "    printProb('alex.')\n",
    "    printProb('alexa.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    plt.plot(range(len(lrAtIx)), lrAtIx, \"black\")\n",
    "    plt.ylim(min(lrAtIx), max(lrAtIx))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    print(\"Actual min max LR\", max(lrAtIx), min(lrAtIx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(fr.h.abs() > 0.99, cmap=\"gray\", interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    ax.set_facecolor(\"#222222\")\n",
    "    #ax.plot(lrAtIx, lossAtIx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    ax.set_facecolor(\"#222222\")\n",
    "    ax.plot(stepIx, lossAtIx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    ax.set_facecolor(\"#222222\")\n",
    "    ax.plot(stepIx, logLossAtIx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if newNet:\n",
    "    pass\n",
    "else:\n",
    "    dim = 0\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    fig.set_facecolor(\"#777777\")\n",
    "    sc = plt.scatter(np.C[:, dim].data, np.C[:,dim + 1].data, s=200)\n",
    "    for i in range(np.C.shape[0]):\n",
    "        plt.text(np.C[i, dim].item(), np.C[i, dim + 1].item(), itos[i], ha=\"center\", va=\"center\", color=\"white\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.C.shape, trX.shape, np.C[trX].shape, np.C[:5], trX[:5], np.C[trX][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8774, -0.6801], [0.8774, -0.6801], [0.8774, -0.6801]]\n",
      "[[0.8774, -0.6801], [0.8774, -0.6801], [0.0965, -0.5708]]\n",
      "[[0.8774, -0.6801], [0.0965, -0.5708], [0.218, -0.382]]\n",
      "[[0.0965, -0.5708], [0.218, -0.382], [-0.5288, 0.7074]]\n",
      "[[0.218, -0.382], [-0.5288, 0.7074], [-0.3088, 0.9816]]\n"
     ]
    }
   ],
   "source": [
    "# Let\"s suppose these are your lists\n",
    "C = [\n",
    "[ 0.8774, -0.6801],\n",
    "         [ 0.1651, -0.5025],\n",
    "         [ 0.2769, -0.3570],\n",
    "         [-0.8820,  0.3902],\n",
    "         [-0.4824,  0.8744],\n",
    "         [-0.3190,  0.7807],\n",
    "         [-0.0100, -0.3401],\n",
    "         [ 0.9975,  2.8280],\n",
    "         [ 0.9623, -1.3172],\n",
    "         [ 0.2180, -0.3820],\n",
    "         [ 0.6139, -0.4287],\n",
    "         [-0.7386,  0.5880],\n",
    "         [-0.3088,  0.9816],\n",
    "         [ 0.3907, -0.4174],\n",
    "         [-0.7380,  0.5205],\n",
    "         [-0.5288,  0.7074],\n",
    "         [-0.3956,  0.9625],\n",
    "         [-0.3802, -0.3504],\n",
    "         [-0.2861,  0.7589],\n",
    "         [ 0.5309, -0.5105],\n",
    "         [-0.0922, -0.6410],\n",
    "         [-0.3823,  0.9899],\n",
    "         [ 0.0965, -0.5708],\n",
    "         [-0.8582, -1.3429],\n",
    "         [-0.4960,  0.2842],\n",
    "         [-0.6105,  0.1336],\n",
    "         [-0.2623,  0.2942]\n",
    "]\n",
    "trX = [\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 22],\n",
    "    [0, 22, 9],\n",
    "    [22, 9, 15],\n",
    "    [9, 15, 12],\n",
    "    # ... More values\n",
    "]\n",
    "\n",
    "# We create a new list to hold the result\n",
    "result = []\n",
    "\n",
    "# We loop over each element in trX\n",
    "for i in range(len(trX)):\n",
    "    temp = []\n",
    "    # Then we loop over each value in the element\n",
    "    for j in range(len(trX[i])):\n",
    "        # We use the value as an index to get the corresponding data from C\n",
    "        temp.append(C[trX[i][j]])\n",
    "    # We add the result to our new list\n",
    "    result.append(temp)\n",
    "\n",
    "# Let\"s log the first 5 elements of the result list\n",
    "for i in range(5):\n",
    "    print(result[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
